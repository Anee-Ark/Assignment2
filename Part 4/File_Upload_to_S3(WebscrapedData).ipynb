{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# File Upload to S3(WebscrapedData)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: boto3 in c:\\users\\devmi\\anaconda3\\lib\\site-packages (1.33.13)\n",
      "Requirement already satisfied: s3transfer<0.9.0,>=0.8.2 in c:\\users\\devmi\\anaconda3\\lib\\site-packages (from boto3) (0.8.2)\n",
      "Requirement already satisfied: jmespath<2.0.0,>=0.7.1 in c:\\users\\devmi\\anaconda3\\lib\\site-packages (from boto3) (1.0.1)\n",
      "Requirement already satisfied: botocore<1.34.0,>=1.33.13 in c:\\users\\devmi\\anaconda3\\lib\\site-packages (from boto3) (1.33.13)\n",
      "Requirement already satisfied: urllib3<1.27,>=1.25.4; python_version < \"3.10\" in c:\\users\\devmi\\anaconda3\\lib\\site-packages (from botocore<1.34.0,>=1.33.13->boto3) (1.25.11)\n",
      "Requirement already satisfied: python-dateutil<3.0.0,>=2.1 in c:\\users\\devmi\\anaconda3\\lib\\site-packages (from botocore<1.34.0,>=1.33.13->boto3) (2.8.1)\n",
      "Requirement already satisfied: six>=1.5 in c:\\users\\devmi\\anaconda3\\lib\\site-packages (from python-dateutil<3.0.0,>=2.1->botocore<1.34.0,>=1.33.13->boto3) (1.14.0)\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "pip install boto3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "AWS S3 Client Initialization using Boto3\n",
    "The following Python code snippet demonstrates how to initialize a client for interacting with Amazon Web Services (AWS) Simple Storage Service (S3) using the boto3 library.\n",
    "\n",
    "This code performs the following key actions:\n",
    "\n",
    "1) Import Boto3 Library: The boto3 library is the AWS SDK for Python. It allows Python developers to write software that makes use of services like Amazon S3 and Amazon EC2. First, we import the boto3 library.\n",
    "\n",
    "3) Create an S3 Client: We use boto3.client(\"s3\") to create a low-level client representing Amazon Simple Storage Service (S3). This client object provides a one-to-one mapping of the S3 API. You can use this client to add, list, or delete objects and buckets in S3, among other operations.\n",
    "\n",
    "4) Usage: The created s3 client object can be used to perform various actions on AWS S3, like uploading files, listing bucket contents, deleting files, etc. The operations performed with this client will require appropriate AWS credentials configured in your environment, which boto3 automatically detects."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "import boto3\n",
    "s3 = boto3.client(\"s3\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    " A session in boto3 is created\n",
    " \n",
    "1) Importing boto3: It's assumed that boto3 has already been imported in a previous part of the notebook. boto3 is the AWS SDK for Python, providing an easy to use, object-oriented API as well as low-level access to AWS services.\n",
    "\n",
    "2) Creating a Session: The boto3.Session constructor is used to create a new session.\n",
    "\n",
    "3) Passing Credentials: The session is initialized with AWS credentials, which are passed as parameters:\n",
    "\n",
    "4) aws_access_key_id: This is  AWS Access Key ID, acting like a username to identify your AWS account.\n",
    "5) aws_secret_access_key: This is AWS Secret Access Key, working like a password. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "aws_access_key_id = 'AKIA4MTWHTESY6QTXXEJ'\n",
    "aws_secret_access_key = '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'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "session = boto3.Session(\n",
    "    aws_access_key_id=aws_access_key_id,\n",
    "    aws_secret_access_key=aws_secret_access_key,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "s3 = session.client('s3')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The file path to be read is mentioned and it is read into filename"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "Assignment = r\"C:\\Users\\devmi\\Downloads\\Assignment.csv\"\n",
    "filename = os.path.basename(Assignment)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The file is uploaded in S3 bucket(bigdatacasestudy2) under the folder(ExtractedData)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "S3_BUCKET_NAME = \"bigdatacasestudy2\"\n",
    "S3_folder = \"ExtractedData/\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(Assignment,\"rb\") as f:\n",
    "    s3.upload_fileobj(f,S3_BUCKET_NAME, S3_folder + filename)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
